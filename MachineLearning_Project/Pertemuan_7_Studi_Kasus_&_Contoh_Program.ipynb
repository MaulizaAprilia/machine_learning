{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4H6s-NZDq6B"
      },
      "source": [
        "# Pertemuan 7 Studi Kasus & Contoh Program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O95sA-6yExj3"
      },
      "source": [
        "# Contoh Program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lASoGT5CXZe"
      },
      "source": [
        "***Program Pertama menggunakan*** K-Fold Cross-Validation dengan Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9xjsUe2CVlz",
        "outputId": "eca177fb-ffbd-4d71-a2ad-fc6124d439fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.96 (+/- 0.02)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris  # Import dataset sebagai contoh\n",
        "\n",
        "# Load dataset Iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target  # Mendefinisikan fitur dan label\n",
        "\n",
        "# Contoh K-Fold Cross-Validation\n",
        "model = RandomForestClassifier()\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Accuracy: {np.mean(scores):.2f} (+/- {np.std(scores):.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLyE7V8oC3V_"
      },
      "source": [
        "***Program Kedua menggunakan*** K-Fold Cross-Validation dengan Train-Test Split dan Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH4FcgnsC421",
        "outputId": "e9ee980b-7e7c-4dad-f599-cf8123ec3834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.97 (+/- 0.02)\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load dataset Iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target  # Mendefinisikan fitur dan label\n",
        "\n",
        "# Membagi data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Contoh K-Fold Cross-Validation\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)  # Melatih model\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Accuracy: {np.mean(scores):.2f} (+/- {np.std(scores):.2f})\")\n",
        "\n",
        "# Prediksi dan Confusion Matrix\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l9abQSpD1JQ"
      },
      "source": [
        "***Program Ketiga*** menggunakan Grid Search untuk Optimasi Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thpN5uNcD_8P",
        "outputId": "eb968313-2d60-4afd-e891-9f7dc7b5e3ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'max_depth': 10, 'n_estimators': 200}\n",
            "Best Score: 0.9583333333333334\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Definisikan model dan parameter grid\n",
        "model = RandomForestClassifier()\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30]\n",
        "}\n",
        "\n",
        "# Grid Search\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNioul69EFiN"
      },
      "source": [
        "***Program Keempat menggunakan*** Random Search untuk Optimasi Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bUXgvB1ENwG",
        "outputId": "e67b4b64-c3d9-4e6f-81ff-fc561a920289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'n_estimators': 200, 'max_depth': 10, 'bootstrap': False}\n",
            "Best Score: 0.9416666666666668\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Definisikan model dan parameter distribusi\n",
        "model = RandomForestClassifier()\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Random Search\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy')\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Score:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxsWEOqREWmW"
      },
      "source": [
        "# Studi kasus klasifikasi Teks: Spam vs. Non-Spam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSWK0gzKEqvo",
        "outputId": "6e232e9e-8f2f-48d8-f231-f8e72885c971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy: 1.0\n",
            "SVM Accuracy: 1.0\n",
            "Best Naive Bayes Parameters: {'alpha': 0.1}\n",
            "Best SVM Parameters: {'C': 0.1, 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1Ô∏è‚É£ Load dataset (contoh dataset sederhana)\n",
        "data = {'text': [\"Gratis hadiah!\", \"Peningkatan akun segera\", \"Meeting jam 10\", \"Beli sekarang diskon 50%\", \"Mari bertemu di kantor\"],\n",
        "        'label': [1, 1, 0, 1, 0]}  # 1 = Spam, 0 = Non-Spam\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 2Ô∏è‚É£ Preprocessing\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "y = df['label']\n",
        "\n",
        "# 3Ô∏è‚É£ Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4Ô∏è‚É£ Grid Search untuk Naive Bayes\n",
        "param_grid_nb = {'alpha': [0.1, 0.5, 1.0, 5]}\n",
        "nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=2) # Adjust cv to 2 or less\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# 5Ô∏è‚É£ Grid Search untuk SVM\n",
        "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "# Similar change for SVM GridSearchCV\n",
        "svm = GridSearchCV(SVC(), param_grid_svm, cv=2)  # Adjust cv to 2 or less\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# 6Ô∏è‚É£ Evaluasi\n",
        "best_nb = nb.best_estimator_\n",
        "best_svm = svm.best_estimator_\n",
        "\n",
        "y_pred_nb = best_nb.predict(X_test)\n",
        "y_pred_svm = best_svm.predict(X_test)\n",
        "\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Best Naive Bayes Parameters:\", nb.best_params_)\n",
        "print(\"Best SVM Parameters:\", svm.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dduqWP-4HGHY"
      },
      "source": [
        "**Berikut penjelasan dari program yang telah dilakukan:**\n",
        "\n",
        "\n",
        "\n",
        "üìå Studi Kasus 1: Klasifikasi Email (Spam vs Non-Spam)\n",
        "\n",
        "üìù Penjelasan:\n",
        "Model tersebut bertujuan untuk mengklasifikasikan email apakah tergolong spam atau bukan.\n",
        "\n",
        "Teknik yang digunakan: Grid Search digunakan untuk mencari parameter terbaik pada dua model, yaitu Naive Bayes dan SVM.\n",
        "\n",
        "Dataset: Contoh data kecil berisi 5 teks email dengan label 1 (Spam) dan 0 (Non-Spam).\n",
        "\n",
        "Evaluasi: Model dilatih menggunakan data pelatihan dan diuji dengan data uji untuk mengukur akurasi.\n",
        "\n",
        "üîç Hasil Output:\n",
        "\n",
        "**Naive Bayes Accuracy: 1.0**\n",
        "\n",
        "**SVM Accuracy: 1.0**\n",
        "\n",
        "**Best Naive Bayes Parameters: {'alpha': 0.1}**\n",
        "\n",
        "**Best SVM Parameters: {'C': 0.1, 'kernel': 'linear'}**\n",
        "\n",
        "üí° Interpretasi Hasil:\n",
        "\n",
        "Akurasi 1.0 (100%) menunjukkan bahwa model berhasil mengklasifikasikan semua email dengan benar dalam data uji.\n",
        "\n",
        "üìà Parameter terbaik:\n",
        "\n",
        "Naive Bayes bekerja optimal dengan alpha = 0.1 (pengaruh smoothing dalam probabilitas).\n",
        "\n",
        "SVM bekerja optimal dengan C = 0.1 dan kernel = linear (pengaruh margin dalam pemisahan data).\n",
        "\n",
        "üî• Kesimpulan:\n",
        "Model tersebut sangat akurat dalam mengklasifikasikan email sebagai spam atau bukan. Namun, dataset yang digunakan terlalu kecil, sehingga perlu diuji dengan data yang lebih besar untuk memastikan keakuratan dalam dunia nyata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js1nftSvFwpe"
      },
      "source": [
        "# Studi kasus prediksi harga rumah dengan random search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DvVp5HPF9Yk",
        "outputId": "bc5d0a0e-8055-42c1-8b8b-0d7d0ffb4a57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest MAE: 59062.5\n",
            "Gradient Boosting MAE: 34927.28657847928\n",
            "Best Random Forest Parameters: {'n_estimators': 200, 'min_samples_split': 10, 'max_depth': None}\n",
            "Best Gradient Boosting Parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.01}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# 1Ô∏è‚É£ Load dataset (contoh dataset sederhana)\n",
        "data = {'size': [50, 100, 150, 200, 250],\n",
        "        'location': [1, 2, 3, 2, 1],  # 1: Suburban, 2: Urban, 3: City Center\n",
        "        'year_built': [2000, 1995, 2010, 2005, 2020],\n",
        "        'price': [100000, 150000, 250000, 200000, 300000]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 2Ô∏è‚É£ Split Data\n",
        "X = df[['size', 'location', 'year_built']]\n",
        "y = df['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3Ô∏è‚É£ Random Search untuk Random Forest\n",
        "param_dist_rf = {'n_estimators': [50, 100, 200], 'max_depth': [None, 5, 10], 'min_samples_split': [2, 5, 10]}\n",
        "rf = RandomizedSearchCV(RandomForestRegressor(), param_distributions=param_dist_rf, n_iter=5, cv=3, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# 4Ô∏è‚É£ Random Search untuk Gradient Boosting\n",
        "param_dist_gb = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]}\n",
        "gb = RandomizedSearchCV(GradientBoostingRegressor(), param_distributions=param_dist_gb, n_iter=5, cv=3, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# 5Ô∏è‚É£ Evaluasi Model\n",
        "best_rf = rf.best_estimator_\n",
        "best_gb = gb.best_estimator_\n",
        "\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "y_pred_gb = best_gb.predict(X_test)\n",
        "\n",
        "print(\"Random Forest MAE:\", mean_absolute_error(y_test, y_pred_rf))\n",
        "print(\"Gradient Boosting MAE:\", mean_absolute_error(y_test, y_pred_gb))\n",
        "print(\"Best Random Forest Parameters:\", rf.best_params_)\n",
        "print(\"Best Gradient Boosting Parameters:\", gb.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_sd-C66Iw1W"
      },
      "source": [
        "**Berikut penjelasan dari program yang telah dilakukan:**\n",
        "\n",
        "üìå Studi Kasus 2: Prediksi Harga Rumah\n",
        "\n",
        "üìù Penjelasan singkat:\n",
        "Model tersebut bertujuan untuk memprediksi harga rumah berdasarkan ukuran, lokasi, dan tahun bangunan.\n",
        "\n",
        "Teknik yang digunakan: Random Search digunakan untuk menemukan kombinasi parameter terbaik pada Random Forest dan Gradient Boosting.\n",
        "\n",
        "Dataset: Contoh data kecil berisi informasi 5 rumah dengan fitur ukuran, lokasi, tahun dibangun, dan harga.\n",
        "\n",
        "Evaluasi: Model dievaluasi dengan Mean Absolute Error (MAE), yang mengukur seberapa jauh prediksi dari harga sebenarnya.\n",
        "\n",
        "üîç Hasil Output:\n",
        "\n",
        "**Random Forest MAE: 64000.0**\n",
        "\n",
        "**Gradient Boosting MAE: 34927.29**\n",
        "\n",
        "**Best Random Forest Parameters: {'n_estimators': 200, 'min_samples_split': 10, 'max_depth': None}**\n",
        "\n",
        "**Best Gradient Boosting Parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.01}**\n",
        "\n",
        "üí° Interpretasi Hasil:\n",
        "\n",
        "Random Forest MAE = 64,000 berarti prediksi harga rumah rata-rata meleset sebesar 64 ribu dari harga sebenarnya.\n",
        "\n",
        "Gradient Boosting MAE = 34,927.29 menunjukkan bahwa model ini lebih baik dalam memprediksi harga karena kesalahan lebih kecil.\n",
        "\n",
        "üìà Parameter terbaik:\n",
        "\n",
        "Random Forest bekerja optimal dengan 200 pohon keputusan, min_samples_split = 10, dan max_depth = None.\n",
        "\n",
        "Gradient Boosting optimal dengan 200 pohon keputusan, max_depth = 7, dan learning_rate = 0.01.\n",
        "\n",
        "üî• Kesimpulan:\n",
        "\n",
        "Gradient Boosting menghasilkan prediksi yang lebih akurat dibandingkan Random Forest dalam studi kasus ini. Namun, hasil dapat bervariasi tergantung pada dataset yang lebih besar dan parameter yang diuji lebih lanjut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaLsB1ybJ1va"
      },
      "source": [
        "# Kesimpulan Studi Kasus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jotD-IfJ5zq"
      },
      "source": [
        "üí°Studi Kasus 1 (Klasifikasi Email)\n",
        "\n",
        "berhasil dengan akurasi tinggi (100%), tetapi perlu diuji dengan lebih banyak data untuk validasi lebih lanjut.\n",
        "\n",
        "üí°Studi Kasus 2 (Prediksi Harga Rumah)\n",
        "\n",
        " menunjukkan bahwa Gradient Boosting lebih akurat daripada Random Forest, karena memiliki kesalahan prediksi yang lebih kecil (MAE lebih rendah).\n",
        "\n",
        "Teknik optimasi parameter (Grid Search dan Random Search) sangat membantu dalam meningkatkan performa model dengan menemukan kombinasi parameter terbaik.\n",
        "\n",
        "‚úÖ Jadi dengan menggunakan metode Machine Learning yang tepat dan optimasi parameter, hasil prediksi dan klasifikasi dapat ditingkatkan secara signifikan!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
